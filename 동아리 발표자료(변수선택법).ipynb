{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb88512d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c9d96f",
   "metadata": {},
   "source": [
    "# Forward Selection (전진 선택법)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8bf67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 전진 선택법\n",
    "variables = df.columns[:].tolist() ## 설명 변수 리스트\n",
    " \n",
    "y = df['반응변수'] ## 반응 변수\n",
    "selected_variables = [] ## 선택된 변수들 (아래 for 문에서 쓰임)\n",
    "sl_enter = 0.05\n",
    " \n",
    "sv_per_step = [] ## 각 스텝별로 선택된 변수들\n",
    "adjusted_r_squared = [] ## 각 스텝별 수정된 결정계수\n",
    "steps = [] ## 스텝\n",
    "step = 0\n",
    "while len(variables) > 0:\n",
    "    remainder = list(set(variables) - set(selected_variables))\n",
    "    pval = pd.Series(index=remainder) ## 변수의 p-value\n",
    "    ## 기존에 포함된 변수와 새로운 변수 하나씩 돌아가면서 \n",
    "    ## 선형 모형을 적합한다.\n",
    "    for col in remainder: \n",
    "        X = df[selected_variables+[col]]\n",
    "        X = sm.add_constant(X)\n",
    "        model = sm.OLS(y,X).fit()\n",
    "        pval[col] = model.pvalues[col]\n",
    " \n",
    "    min_pval = pval.min()\n",
    "    if min_pval < sl_enter: ## 최소 p-value 값이 기준 값(0.05)보다 작으면 포함\n",
    "        selected_variables.append(pval.idxmin())\n",
    "        \n",
    "        step += 1\n",
    "        steps.append(step)\n",
    "        adj_r_squared = sm.OLS(y,sm.add_constant(df[selected_variables])).fit().rsquared_adj\n",
    "        adjusted_r_squared.append(adj_r_squared)\n",
    "        sv_per_step.append(selected_variables.copy())\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7058cf35",
   "metadata": {},
   "source": [
    "# Backward Elimination(후진 소거법)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f957d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 후진 소거법\n",
    "variables = df.columns[:].tolist() ## 설명 변수 리스트\n",
    " \n",
    "y = df['반응변수'] ## 반응 변수\n",
    "selected_variables = variables ## 초기에는 모든 변수가 선택된 상태 - 소거법이기 때문\n",
    "sl_remove = 0.05\n",
    " \n",
    "sv_per_step = [] ## 각 스텝별로 선택된 변수들\n",
    "adjusted_r_squared = [] ## 각 스텝별 수정된 결정계수\n",
    "steps = [] ## 스텝\n",
    "step = 0\n",
    "while len(selected_variables) > 0:\n",
    "    X = sm.add_constant(df[selected_variables])\n",
    "    p_vals = sm.OLS(y,X).fit().pvalues[1:] ## 절편항의 p-value는 뺀다 꼭 빼지 않아도 됨.\n",
    "    max_pval = p_vals.max() ## 최대 p-value\n",
    "    if max_pval >= sl_remove: ## 최대 p-value값이 기준값보다 크거나 같으면 제외\n",
    "        remove_variable = p_vals.idxmax()\n",
    "        selected_variables.remove(remove_variable)\n",
    " \n",
    "        step += 1\n",
    "        steps.append(step)\n",
    "        adj_r_squared = sm.OLS(y,sm.add_constant(df[selected_variables])).fit().rsquared_adj\n",
    "        adjusted_r_squared.append(adj_r_squared)\n",
    "        sv_per_step.append(selected_variables.copy())\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527ce394",
   "metadata": {},
   "source": [
    "# Forward Step Wise Selection(단계적 선택법)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566c44b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 전진 단계별 선택법\n",
    "variables = df.columns[:].tolist() ## 설명 변수 리스트\n",
    " \n",
    "y = df['반응변수'] ## 반응 변수\n",
    "selected_variables = [] ## 선택된 변수들\n",
    "sl_enter = 0.05\n",
    "sl_remove = 0.05\n",
    " \n",
    "sv_per_step = [] ## 각 스텝별로 선택된 변수들\n",
    "adjusted_r_squared = [] ## 각 스텝별 수정된 결정계수\n",
    "steps = [] ## 스텝\n",
    "step = 0\n",
    "while len(variables) > 0:\n",
    "    remainder = list(set(variables) - set(selected_variables))\n",
    "    pval = pd.Series(index=remainder) ## 변수의 p-value\n",
    "    ## 기존에 포함된 변수와 새로운 변수 하나씩 돌아가면서 \n",
    "    ## 선형 모형을 적합한다.\n",
    "    for col in remainder: \n",
    "        X = df[selected_variables+[col]]\n",
    "        X = sm.add_constant(X)\n",
    "        model = sm.OLS(y,X).fit()\n",
    "        pval[col] = model.pvalues[col]\n",
    " \n",
    "    min_pval = pval.min()\n",
    "    if min_pval < sl_enter: ## 최소 p-value 값이 기준 값보다 작으면 포함\n",
    "        selected_variables.append(pval.idxmin())\n",
    "        ## 선택된 변수들에대해서\n",
    "        ## 어떤 변수를 제거할지 고른다.\n",
    "        while len(selected_variables) > 0:\n",
    "            selected_X = df[selected_variables]\n",
    "            selected_X = sm.add_constant(selected_X)\n",
    "            selected_pval = sm.OLS(y,selected_X).fit().pvalues[1:] ## 절편항의 p-value는 뺀다.(안 빼도 무관->이건 분석가의 판단)\n",
    "            max_pval = selected_pval.max()\n",
    "            if max_pval >= sl_remove: ## 최대 p-value값이 기준값보다 크거나 같으면 제외\n",
    "                remove_variable = selected_pval.idxmax()\n",
    "                selected_variables.remove(remove_variable)\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        step += 1\n",
    "        steps.append(step)\n",
    "        adj_r_squared = sm.OLS(y,sm.add_constant(df[selected_variables])).fit().rsquared_adj\n",
    "        adjusted_r_squared.append(adj_r_squared)\n",
    "        sv_per_step.append(selected_variables.copy())\n",
    "    else:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4aadc0c",
   "metadata": {},
   "source": [
    "# R2, AIC, BIC, Cp, PRESS\n",
    "### 단점 : matrics 형태로 바꾸어 모든 상황에 대한 결과값을 도출해내기 때문에 시간적 소요가 많이 들고, <br> 데이터수가 많을경우 사용이 어려움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ec6c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = ols('종속변수~독립변수', data= df).fit()\n",
    " \n",
    "## hat matrix 계산\n",
    "X = np.array(df[['독립변수']]) ## Model matrix for full model\n",
    " \n",
    "X_tX = np.matmul(X.transpose(),X)\n",
    "X_tX_inv = np.linalg.inv(X_tX)\n",
    "hat_matrix = np.matmul(np.matmul(X,X_tX_inv),X.transpose()) ## hat matrix\n",
    "diagonals = np.array([hat_matrix[i][i] for i in range(len(df))]) ## hat matrix의 대각원소\n",
    " \n",
    "response = '종속변수'\n",
    "y = df[response] ## 반응 변수 벡터\n",
    "variables = ['독립변수'] ## 총 변수집합\n",
    " \n",
    "num_var = len(variables) ## 총 변수 개수\n",
    "num_data = len(df) ## 데이터 개수\n",
    "mse_full = fit.mse_resid ## 모든 변수를 포함한 mean square residual\n",
    "mean_response = np.mean(y) ## y의 평균\n",
    " \n",
    "cp_list = [] ## Mallow's C\n",
    "ad_r_list = [] ## 수정된 결정계수\n",
    "aic_list = [] ## Akaike's information criterion\n",
    "bic_list = [] ## Bayes information criterion\n",
    "press_list = [] ## press criterion\n",
    " \n",
    "num_parameter = [] ## 파라미터 즉 절편을 포함한 회귀계수의 개수\n",
    "subsets = [] ## 변수의 집합\n",
    "for p in range(num_var+1):\n",
    "    if p == 0: ## 절편만 있는 모형\n",
    "        var_exp = '1'\n",
    "        exp = response + ' ~ ' + var_exp\n",
    "        subsets.append('None') ## 절편만 있고 변수는 없음\n",
    "        sub_fit = ols(exp,data=df).fit() ## 절편만 있는 모형 적합\n",
    "        sse = np.sum(np.square(sub_fit.resid)) ## square sum of residual\n",
    "        sst = np.sum(np.square(y-mean_response)) ## total sum of square\n",
    "        cp = sse/mse_full - (num_data-2*(p+1)) ## Mallow's C\n",
    "        ad_r = 0 ## 수정된 결정계수 절편만 있다면 수정된 결정계수 값은 0\n",
    "        aic = num_data*np.log(sse) - num_data*np.log(num_data) + 2*(p+1) ## Akaike's information criterion\n",
    "        bic = num_data*np.log(sse) - num_data*np.log(num_data) + np.log(num_data)*(p+1) ## Bayes information criterion\n",
    "        press = np.sum(np.square(np.divide(sub_fit.resid,1-diagonals))) ## press\n",
    "        cp_list.append(cp)\n",
    "        ad_r_list.append(ad_r)\n",
    "        aic_list.append(aic)\n",
    "        bic_list.append(bic)\n",
    "        press_list.append(press)\n",
    "        num_parameter.append(p+1)\n",
    "    else:\n",
    "        selected_var = combinations(variables,p)\n",
    "        for s in selected_var:\n",
    "            var_exp = '+'.join(s)\n",
    "            exp = response + ' ~ ' + var_exp\n",
    "            subsets.append(', '.join(s))\n",
    "            sub_fit = ols(exp,data=df).fit()\n",
    "            sse = np.sum(np.square(sub_fit.resid)) \n",
    "            sst = np.sum(np.square(y-np.mean(y))) \n",
    "            cp = sse/mse_full - (num_data-2*(p+1))\n",
    "            ad_r = 1 - ((num_data-1)/(num_data-p-1))*(sse/sst) # 이부분 떄문에 새로운 for문 생성 \n",
    "            aic = num_data*np.log(sse) - num_data*np.log(num_data) + 2*(p+1)\n",
    "            bic = num_data*np.log(sse) - num_data*np.log(num_data) + np.log(num_data)*(p+1)\n",
    "            press = np.sum(np.square(np.divide(sub_fit.resid,1-diagonals)))\n",
    "            cp_list.append(cp)\n",
    "            ad_r_list.append(ad_r)\n",
    "            aic_list.append(aic)\n",
    "            bic_list.append(bic)\n",
    "            press_list.append(press)\n",
    "            num_parameter.append(p+1)\n",
    " \n",
    "data_res = pd.DataFrame()\n",
    "data_res['Variables'] = subsets\n",
    "data_res['Number_of_parameter'] = num_parameter\n",
    "data_res['Ad_R'] = ad_r_list\n",
    "data_res['Cp'] = cp_list\n",
    "data_res['AIC'] = aic_list\n",
    "data_res['BIC'] = bic_list\n",
    "data_res['PRESS'] = press_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
